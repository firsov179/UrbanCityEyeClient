# -*- coding: utf-8 -*-
"""Копия_блокнота__model_ipynb_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z__W0ecoANJBDmcrj1Jqh5GDaboua3le
"""

!pip install tensorflow

!pip install scipy

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import re
import glob
from datetime import datetime
from google.colab import drive
import gc
from PIL import Image
import h5py
import math
import time
import os
import numpy as np
import tensorflow as tf

# Монтируем Google Drive
drive.mount('/content/drive')

# Путь к данным на Google Drive
BASE_DIR = '/content/drive/MyDrive/diplom/London'

from google.colab import drive
drive.mount('/content/drive')

# Константы
# Оригинальное разрешение
ORIG_HEIGHT = 4631
ORIG_WIDTH = 7750

# Уменьшаем размер фрагмента для более эффективного использования памяти
PATCH_SIZE = 256  # Размер одного фрагмента (квадратный)
PATCH_OVERLAP = 64  # Перекрытие между фрагментами
NUM_CHANNELS = 3  # RGB изображения
SEQUENCE_LENGTH = 15  # Количество последовательных карт для предсказания следующей
BATCH_SIZE = 2  # Размер батча для фрагментов
EPOCHS = 15
LEARNING_RATE = 0.0001

# Создаем директорию для промежуточных данных и результатов
OUTPUT_DIR = os.path.join(BASE_DIR, 'results_fullres')
PATCHES_DIR = os.path.join(OUTPUT_DIR, 'patches')
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(PATCHES_DIR, exist_ok=True)

def extract_year(filename):
    """Извлекает год из имени файла"""
    year = re.search(r'(\d+)\.png', filename)
    if year:
        return int(year.group(1))
    return None

def process_image_to_patches(img_path, output_dir=PATCHES_DIR, patch_size=PATCH_SIZE, overlap=PATCH_OVERLAP):
    """Обрабатывает одно изображение, сохраняя его фрагменты на диск"""
    # Извлекаем год
    year = extract_year(os.path.basename(img_path))
    if year is None:
        print(f"Не удалось извлечь год из: {img_path}")
        return None, []

    # Создаем директорию для фрагментов этого года
    year_dir = os.path.join(output_dir, str(year))
    os.makedirs(year_dir, exist_ok=True)

    try:
        # Загружаем изображение через PIL для оптимизации памяти
        pil_img = Image.open(img_path)
        width, height = pil_img.size

        # Убеждаемся, что изображение в RGB
        if pil_img.mode != 'RGB':
            pil_img = pil_img.convert('RGB')

        # Вычисляем шаг между центрами фрагментов
        stride = patch_size - overlap

        # Вычисляем количество фрагментов по высоте и ширине
        n_h = math.ceil((height - patch_size) / stride) + 1
        n_w = math.ceil((width - patch_size) / stride) + 1

        print(f"Обработка изображения {year} года, размер: {width}x{height}, фрагментов: {n_h * n_w}")

        # Список позиций фрагментов для восстановления
        patch_positions = []

        # Извлекаем фрагменты
        for i in range(n_h):
            for j in range(n_w):
                # Вычисляем координаты верхнего левого угла фрагмента
                y_start = min(i * stride, height - patch_size)
                x_start = min(j * stride, width - patch_size)

                # Вырезаем фрагмент из изображения
                patch = pil_img.crop((x_start, y_start, x_start + patch_size, y_start + patch_size))

                # Сохраняем фрагмент на диск
                patch_filename = f"{year}_{y_start}_{x_start}.png"
                patch_path = os.path.join(year_dir, patch_filename)
                patch.save(patch_path)

                # Сохраняем позицию фрагмента
                patch_positions.append((y_start, x_start))

                # Периодически очищаем память
                if (i * n_w + j + 1) % 100 == 0:
                    gc.collect()

        # Сохраняем информацию о позициях фрагментов
        positions_file = os.path.join(year_dir, "positions.npy")
        np.save(positions_file, np.array(patch_positions))

        print(f"Сохранено {len(patch_positions)} фрагментов для {year} года")
        return year, patch_positions

    except Exception as e:
        print(f"Ошибка при обработке {img_path}: {e}")
        import traceback
        traceback.print_exc()
        return None, []

def preprocess_all_images(image_paths):
    """Обрабатывает все изображения, сохраняя фрагменты на диск"""
    # Сортируем изображения по годам
    sorted_paths = sorted(image_paths, key=lambda x: extract_year(os.path.basename(x)))

    years_processed = []
    all_positions = {}

    for img_path in sorted_paths:
        # Очищаем память перед обработкой каждого изображения
        gc.collect()

        # Обрабатываем изображение и сохраняем фрагменты
        year, positions = process_image_to_patches(img_path)

        if year is not None:
            years_processed.append(year)
            all_positions[year] = positions

            # Сохраняем промежуточные результаты
            np.save(os.path.join(OUTPUT_DIR, "years_processed.npy"), np.array(years_processed))

            # Даем время на сбор мусора и охлаждение GPU
            time.sleep(2)

    return years_processed, all_positions

def build_sequences_index(years_processed, all_positions, seq_length=SEQUENCE_LENGTH):
    """Создает индекс последовательностей для обучения без загрузки всех фрагментов в память"""
    print("Создание индекса последовательностей...")

    # Сортируем годы
    sorted_years = sorted(years_processed)

    sequences = []

    # Для каждой возможной последовательности годов
    for i in range(len(sorted_years) - seq_length):
        # Получаем последовательность годов
        year_sequence = sorted_years[i:i+seq_length+1]

        # Для каждой позиции фрагмента в первом году последовательности
        for pos in all_positions[year_sequence[0]]:
            # Проверяем, есть ли фрагменты на той же позиции во всех годах последовательности
            sequence_valid = True

            for year in year_sequence[1:]:
                if pos not in all_positions[year]:
                    sequence_valid = False
                    break

            # Если последовательность действительна, добавляем ее в список
            if sequence_valid:
                # Создаем запись [годы, позиция]
                sequences.append([year_sequence, pos])

    print(f"Создано {len(sequences)} записей последовательностей")

    # Сохраняем индекс последовательностей
    np.save(os.path.join(OUTPUT_DIR, "sequences_index.npy"), np.array(sequences, dtype=object))

    return sequences


def build_patch_convlstm_model(input_shape=(SEQUENCE_LENGTH, PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS)):
    """Создает модель ConvLSTM для обработки фрагментов изображений"""
    model = models.Sequential()

    # Первый блок ConvLSTM
    model.add(layers.ConvLSTM2D(
        filters=16,
        kernel_size=(3, 3),
        padding='same',
        return_sequences=True,
        activation='relu',
        input_shape=input_shape
    ))
    model.add(layers.BatchNormalization())

    # Второй блок ConvLSTM
    model.add(layers.ConvLSTM2D(
        filters=64,
        kernel_size=(3, 3),
        padding='same',
        return_sequences=False,  # Изменено с True на False чтобы удалить временное измерение
        activation='relu'
    ))
    model.add(layers.BatchNormalization())

    # Выходная сверточная часть
    model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(filters=NUM_CHANNELS, kernel_size=(3, 3), activation='sigmoid', padding='same'))

    return model

def sequence_generator(sequences_index, batch_size=BATCH_SIZE):
    """Генератор с оптимизацией памяти"""
    num_sequences = len(sequences_index)

    while True:
        # Перемешиваем индексы последовательностей
        indices = np.random.permutation(num_sequences)

        for start_idx in range(0, num_sequences, batch_size):
            # Принудительная очистка памяти
            gc.collect()

            end_idx = min(start_idx + batch_size, num_sequences)
            batch_indices = indices[start_idx:end_idx]

            X_batch = []
            y_batch = []

            # Загружаем последовательности для текущего батча
            for idx in batch_indices:
                year_sequence, pos = sequences_index[idx]

                # Загружаем входные фрагменты
                input_sequence = []
                for year in year_sequence[:-1]:  # Все кроме последнего года
                    patch_path = os.path.join(PATCHES_DIR, str(year), f"{year}_{pos[0]}_{pos[1]}.png")
                    img = Image.open(patch_path)
                    img_array = np.array(img) / 255.0
                    input_sequence.append(img_array)
                    # Закрываем файл для экономии памяти
                    img.close()

                # Загружаем целевой фрагмент
                target_year = year_sequence[-1]
                target_path = os.path.join(PATCHES_DIR, str(target_year), f"{target_year}_{pos[0]}_{pos[1]}.png")
                target_img = Image.open(target_path)
                target_array = np.array(target_img) / 255.0
                target_img.close()

                X_batch.append(np.array(input_sequence))
                y_batch.append(target_array)

            X_batch_np = np.array(X_batch)
            y_batch_np = np.array(y_batch)

            yield X_batch_np, y_batch_np

            # После выдачи батча очищаем память
            del X_batch, y_batch, X_batch_np, y_batch_np
            gc.collect()

def train_model_with_disk_generator(sequences_index, validation_split=0.2):
    """Значительно оптимизированная версия для быстрого обучения"""
    # Разделяем индекс последовательностей на обучающую и валидационную выборки
    num_sequences = len(sequences_index)

    # РАДИКАЛЬНО уменьшаем количество последовательностей
    max_sequences = 6000  # Очень ограниченное количество для быстрого обучения
    if num_sequences > max_sequences:
        print(f"Радикально ограничиваем количество последовательностей до {max_sequences} (из {num_sequences})")

        # Равномерно выбираем последовательности из разных годов
        # Группируем последовательности по годам первого изображения
        sequences_by_year = {}
        for seq in sequences_index:
            year = seq[0][0]  # Первый год в последовательности
            if year not in sequences_by_year:
                sequences_by_year[year] = []
            sequences_by_year[year].append(seq)

        # Выбираем равномерно из каждого года
        selected_sequences = []
        for year, seqs in sequences_by_year.items():
            # Количество последовательностей для выбора из каждого года
            n_to_select = max(1, int(max_sequences * len(seqs) / num_sequences))
            selected = np.random.choice(len(seqs), min(n_to_select, len(seqs)), replace=False)
            selected_sequences.extend([seqs[i] for i in selected])

        # Если мы выбрали меньше, чем нужно, добавляем случайные
        if len(selected_sequences) < max_sequences:
            remaining = max_sequences - len(selected_sequences)
            remaining_seqs = [seq for seq in sequences_index if seq not in selected_sequences]
            if remaining_seqs:
                additional = np.random.choice(len(remaining_seqs), min(remaining, len(remaining_seqs)), replace=False)
                selected_sequences.extend([remaining_seqs[i] for i in additional])

        # Если мы выбрали больше, чем нужно, обрезаем
        if len(selected_sequences) > max_sequences:
            selected_sequences = selected_sequences[:max_sequences]

        sequences_index = selected_sequences
        num_sequences = len(sequences_index)

    # Разделяем на обучающую и валидационную выборки
    num_val = int(num_sequences * validation_split)
    indices = np.random.permutation(num_sequences)

    train_indices = indices[num_val:]
    val_indices = indices[:num_val]

    train_sequences = [sequences_index[i] for i in train_indices]
    val_sequences = [sequences_index[i] for i in val_indices]

    print(f"Обучающая выборка: {len(train_sequences)} последовательностей")
    print(f"Валидационная выборка: {len(val_sequences)} последовательностей")

    # Создаем генераторы для обучения и валидации
    train_gen = sequence_generator(train_sequences, BATCH_SIZE)
    val_gen = sequence_generator(val_sequences, BATCH_SIZE)

    # Создаем модель
    tf.keras.backend.clear_session()  # Очищаем сессию TensorFlow

    # Уменьшаем размеры модели, но сохраняем архитектуру
    model = models.Sequential()

    # Первый блок ConvLSTM с меньшим числом фильтров
    model.add(layers.ConvLSTM2D(
        filters=16,  # Уменьшено с 16 до 8
        kernel_size=(3, 3),
        padding='same',
        return_sequences=True,
        activation='relu',
        input_shape=(SEQUENCE_LENGTH, PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS)
    ))
    model.add(layers.BatchNormalization())

    # Второй блок ConvLSTM с меньшим числом фильтров
    model.add(layers.ConvLSTM2D(
        filters=64,  # Уменьшено с 64 до 16
        kernel_size=(3, 3),
        padding='same',
        return_sequences=False,  # Удаляем временное измерение
        activation='relu'
    ))
    model.add(layers.BatchNormalization())

    # Выходная сверточная часть с меньшим числом фильтров
    model.add(layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same'))
    model.add(layers.Conv2D(filters=NUM_CHANNELS, kernel_size=(3, 3), activation='sigmoid', padding='same'))

    # Компилируем модель
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Увеличиваем скорость обучения
    model.compile(
        optimizer=optimizer,
        loss='mean_squared_error',
        metrics=['mean_absolute_error']
    )

    model.summary()

    # Создаем только один коллбэк - сохранение лучшей модели
    checkpoint = ModelCheckpoint(
        os.path.join(OUTPUT_DIR, 'city_growth_model_best.h5'),
        monitor='val_loss',
        save_best_only=True,
        mode='min',
        verbose=1
    )

    # МИНИМАЛЬНОЕ количество шагов для быстрого обучения
    steps_per_epoch = 10
    validation_steps = 5

    # ОЧЕНЬ небольшое количество эпох
    epochs = 10

    print(f"Шагов на эпоху: {steps_per_epoch}, валидационных шагов: {validation_steps}, эпох: {epochs}")

    # Обучаем модель с минимальным временем
    print("Начало быстрого обучения модели...")

    history = model.fit(
        train_gen,
        steps_per_epoch=steps_per_epoch,
        validation_data=val_gen,
        validation_steps=validation_steps,
        epochs=epochs,
        callbacks=[checkpoint],
        verbose=1
    )

    # Сохраняем модель и историю обучения
    model.save(os.path.join(OUTPUT_DIR, 'city_growth_model_final.h5'))

    # Краткая история обучения
    plt.figure(figsize=(15, 6))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['mean_absolute_error'], label='Train MAE')
    plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')
    plt.title('Mean Absolute Error')
    plt.xlabel('Epoch')
    plt.ylabel('MAE')
    plt.legend()

    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, 'training_history.png'))

    # Сохраняем историю обучения в CSV
    import pandas as pd
    history_df = pd.DataFrame(history.history)
    history_df.to_csv(os.path.join(OUTPUT_DIR, 'training_history.csv'), index=False)

    print("Обучение успешно завершено за короткое время!")
    return model, history

def predict_next_year_seamless(model, year_sequence, patch_positions, output_dir=OUTPUT_DIR):
    """
    Улучшенная функция предсказания с бесшовными переходами между фрагментами
    и правильной цветопередачей
    """
    last_year = year_sequence[-1]
    next_year = last_year + 5  # Предполагаем шаг в 5 лет

    print(f"Создание бесшовного прогноза на {next_year} год на основе годов {year_sequence}")

    # Загружаем базовое изображение последнего года
    try:
        last_img_path = os.path.join(BASE_DIR, "maps_by_years_image", f"{last_year}.png")
        if os.path.exists(last_img_path):
            print(f"Загружаем последнее известное изображение: {last_img_path}")
            base_img = Image.open(last_img_path)
            # Извлекаем информацию о цвете фона из верхнего левого угла
            bg_sample = np.array(base_img)[:100, :100]
            background_color = np.median(bg_sample.reshape(-1, 3), axis=0) / 255.0
            print(f"Определен цвет фона: {background_color}")
            base_array = np.array(base_img) / 255.0
            base_img.close()
        else:
            print("Последнее известное изображение не найдено, создаем чисто белое изображение.")
            background_color = np.array([1.0, 1.0, 1.0])
            base_array = np.ones((ORIG_HEIGHT, ORIG_WIDTH, NUM_CHANNELS))
    except Exception as e:
        print(f"Ошибка при загрузке базового изображения: {e}")
        background_color = np.array([1.0, 1.0, 1.0])
        base_array = np.ones((ORIG_HEIGHT, ORIG_WIDTH, NUM_CHANNELS))

    # 1. ПРЕДВАРИТЕЛЬНЫЙ ЭТАП: Уменьшаем размер изображения для быстрого первого прохода
    scale_factor = 0.1  # 10% от оригинального размера
    small_height = int(ORIG_HEIGHT * scale_factor)
    small_width = int(ORIG_WIDTH * scale_factor)
    small_patch_size = int(PATCH_SIZE * scale_factor)

    print(f"Создание предварительного изображения размером {small_width}x{small_height}")

    # Создаем уменьшенную версию базового изображения
    base_small = Image.fromarray((base_array * 255).astype(np.uint8))
    base_small = base_small.resize((small_width, small_height), Image.LANCZOS)
    small_base_array = np.array(base_small) / 255.0

    # Создаем новое изображение для прогноза уменьшенного размера
    small_result = np.full((small_height, small_width, NUM_CHANNELS), background_color)

    # 2. ОСНОВНОЙ ЭТАП: Полноразмерное прогнозирование с перекрытием
    print("Создание полноразмерного прогноза с перекрытием")

    # Создаем новое изображение для окончательного результата
    full_result = np.full((ORIG_HEIGHT, ORIG_WIDTH, NUM_CHANNELS), background_color)
    weights = np.zeros((ORIG_HEIGHT, ORIG_WIDTH))

    # Использование окна с плавным взвешиванием для устранения видимых краев
    def gaussian_weight(size):
        """Создает гауссово окно весов для сглаживания границ"""
        x = np.linspace(-1, 1, size)
        y = np.linspace(-1, 1, size)
        x, y = np.meshgrid(x, y)
        g = np.exp(-(x**2 + y**2) / 0.5)
        return g / g.max()

    # Создаем веса для сглаживания
    weight_window = gaussian_weight(PATCH_SIZE)

    # Определяем шаг между центрами фрагментов (с перекрытием)
    overlap = PATCH_SIZE // 2  # 50% перекрытие
    stride = PATCH_SIZE - overlap

    # Создаем сетку позиций с перекрытием
    grid_positions = []
    for y in range(0, ORIG_HEIGHT - PATCH_SIZE + 1, stride):
        for x in range(0, ORIG_WIDTH - PATCH_SIZE + 1, stride):
            grid_positions.append((y, x))

    print(f"Создано {len(grid_positions)} позиций сетки с перекрытием 50%")

    # Находим ближайший реальный фрагмент для каждой позиции в сетке
    grid_to_real = {}
    for grid_pos in grid_positions:
        grid_y, grid_x = grid_pos

        # Находим ближайший реальный фрагмент
        min_dist = float('inf')
        closest_pos = None

        for pos in patch_positions:
            real_y, real_x = pos
            dist = ((real_y - grid_y) ** 2 + (real_x - grid_x) ** 2) ** 0.5
            if dist < min_dist:
                min_dist = dist
                closest_pos = pos

        if closest_pos is not None:
            grid_to_real[grid_pos] = closest_pos

    # Обрабатываем сетку батчами
    batch_size = 4
    processed_count = 0

    for i in range(0, len(grid_positions), batch_size):
        # Очищаем память
        gc.collect()

        batch_grid_positions = grid_positions[i:i+batch_size]
        X_batch = []
        valid_grid_positions = []

        # Загружаем фрагменты для каждой позиции сетки
        for grid_pos in batch_grid_positions:
            if grid_pos in grid_to_real:
                real_pos = grid_to_real[grid_pos]

                # Загружаем последовательность фрагментов
                input_sequence = []
                valid_sequence = True

                for year in year_sequence:
                    patch_path = os.path.join(PATCHES_DIR, str(year), f"{year}_{real_pos[0]}_{real_pos[1]}.png")
                    if os.path.exists(patch_path):
                        img = Image.open(patch_path)
                        # Убеждаемся в правильном размере
                        if img.size[0] != PATCH_SIZE or img.size[1] != PATCH_SIZE:
                            img = img.resize((PATCH_SIZE, PATCH_SIZE), Image.LANCZOS)
                        img_array = np.array(img) / 255.0
                        input_sequence.append(img_array)
                        img.close()
                    else:
                        valid_sequence = False
                        break

                if valid_sequence and len(input_sequence) == len(year_sequence):
                    X_batch.append(input_sequence)
                    valid_grid_positions.append(grid_pos)

        if not X_batch:
            continue

        # Предсказываем фрагменты
        X_batch_array = np.array(X_batch)
        predictions = model.predict(X_batch_array, verbose=0)

        # Обновляем результат с весовым сглаживанием
        for grid_pos, pred in zip(valid_grid_positions, predictions):
            grid_y, grid_x = grid_pos

            # Обрезаем размер фрагмента, если он выходит за границы
            patch_h, patch_w = pred.shape[:2]
            effective_h = min(patch_h, ORIG_HEIGHT - grid_y)
            effective_w = min(patch_w, ORIG_WIDTH - grid_x)

            if effective_h <= 0 or effective_w <= 0:
                continue

            # Коррекция цвета - преобразуем все неосновные цвета к белому фону
            # Это предотвращает появление желтого оттенка
            pred_corrected = pred.copy()

            # Определяем области, которые должны быть белым фоном
            # (предполагаем, что фон соответствует пикселям со значениями > 0.8)
            high_value_mask = np.all(pred > 0.8, axis=-1)

            # Преобразуем эти области в чисто белые
            for c in range(NUM_CHANNELS):
                pred_corrected[high_value_mask, c] = 1.0

            # Применяем весовое окно для сглаживания границ
            effective_weight = weight_window[:effective_h, :effective_w]

            # Обновляем изображение с весами
            for c in range(NUM_CHANNELS):
                full_result[grid_y:grid_y+effective_h, grid_x:grid_x+effective_w, c] += pred_corrected[:effective_h, :effective_w, c] * effective_weight

            # Обновляем веса
            weights[grid_y:grid_y+effective_h, grid_x:grid_x+effective_w] += effective_weight

        processed_count += len(valid_grid_positions)
        print(f"Обработано {processed_count}/{len(grid_positions)} позиций сетки")

        # Сохраняем промежуточные результаты
        if processed_count % 100 == 0 or processed_count >= len(grid_positions):
            # Нормализуем промежуточный результат
            temp_result = full_result.copy()
            temp_weights = weights.copy()

            # Нормализуем только области с ненулевыми весами
            mask = temp_weights > 0
            for c in range(NUM_CHANNELS):
                temp_result[mask, c] = temp_result[mask, c] / temp_weights[mask]

            # Для областей с нулевыми весами используем базовое изображение
            zero_mask = ~mask
            if np.any(zero_mask):
                for c in range(NUM_CHANNELS):
                    temp_result[zero_mask, c] = base_array[zero_mask, c]

            # Применяем пороговое значение для преобразования почти белых пикселей в полностью белые
            # Это устраняет проблему с желтым оттенком
            white_mask = np.all(temp_result > 0.85, axis=-1)
            for c in range(NUM_CHANNELS):
                temp_result[white_mask, c] = 1.0

            # Сохраняем промежуточный результат
            temp_img = Image.fromarray((temp_result * 255).astype(np.uint8))
            temp_path = os.path.join(output_dir, f"temp_prediction_{next_year}_{processed_count}.png")
            temp_img.save(temp_path)
            print(f"Промежуточный результат сохранен: {temp_path}")

    # Нормализуем итоговый результат
    final_result = full_result.copy()
    final_weights = weights.copy()

    # Нормализуем области с ненулевыми весами
    mask = final_weights > 0
    for c in range(NUM_CHANNELS):
        final_result[mask, c] = final_result[mask, c] / final_weights[mask]

    # Для областей с нулевыми весами используем базовое изображение
    zero_mask = ~mask
    if np.any(zero_mask):
        for c in range(NUM_CHANNELS):
            final_result[zero_mask, c] = base_array[zero_mask, c]

    # Применяем пороговое значение для преобразования почти белых пикселей в полностью белые
    white_mask = np.all(final_result > 0.85, axis=-1)
    for c in range(NUM_CHANNELS):
        final_result[white_mask, c] = 1.0

    # Применяем сглаживание для удаления оставшихся артефактов
    try:
        from scipy.ndimage import gaussian_filter
        smoothed_result = final_result.copy()
        for c in range(NUM_CHANNELS):
            smoothed_result[:, :, c] = gaussian_filter(final_result[:, :, c], sigma=0.5)
        final_result = smoothed_result
        print("Применено гауссово сглаживание")
    except:
        print("Не удалось применить сглаживание")

    # Повторно применяем коррекцию белого
    white_mask = np.all(final_result > 0.85, axis=-1)
    for c in range(NUM_CHANNELS):
        final_result[white_mask, c] = 1.0

    # Сохраняем окончательный результат
    final_path = os.path.join(output_dir, f"seamless_prediction_{next_year}.png")
    final_img = Image.fromarray((final_result * 255).astype(np.uint8))
    final_img.save(final_path)
    print(f"Окончательное бесшовное изображение сохранено: {final_path}")

    return next_year, final_result

def main(skip_phases=0, only_prediction=False):
    """
    Основная функция с возможностью пропуска любых фаз

    skip_phases: количество фаз для пропуска (0-3)
    0 - выполнить все фазы
    1 - пропустить предобработку (Фаза 1)
    2 - пропустить предобработку и создание индекса (Фазы 1 и 2)
    3 - пропустить предобработку, создание индекса и обучение (Фазы 1, 2 и 3)

    only_prediction: если True, выполнить только предсказание (Фаза 4)
                    загрузив модель с диска (эквивалентно skip_phases=3)
    """
    # Если only_prediction=True, устанавливаем skip_phases=3, чтобы пропустить все, кроме предсказания
    if only_prediction:
        skip_phases = 3

    # Настраиваем GPU
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"Обнаружено {len(gpus)} GPU устройств, динамическое выделение памяти включено")
        except RuntimeError as e:
            print(f"Ошибка при настройке GPU: {e}")

    # Для пропуска фаз нам нужно загрузить созданные ранее данные
    years_processed = None
    all_positions = {}
    sequences_index = None
    model = None

    # Фаза 1: Предобработка - разделение изображений на фрагменты
    if skip_phases < 1:
        print("Фаза 1: Разделение изображений на фрагменты и сохранение на диск...")
        # Получаем пути ко всем изображениям
        data_dir = BASE_DIR
        image_paths = glob.glob(os.path.join(data_dir, "*.png"))

        # Проверяем, что файлы найдены
        if not image_paths:
            print(f"Ошибка: изображения не найдены в директории {data_dir}")
            return

        print(f"Найдено {len(image_paths)} изображений")
        years_processed, all_positions = preprocess_all_images(image_paths)

        if not years_processed:
            print("Не удалось обработать ни одного изображения.")
            return

        print(f"Успешно обработано {len(years_processed)} изображений")
    else:
        print("Пропуск Фазы 1 (предполагается, что фрагменты уже созданы)")
        # Загружаем информацию о предобработанных изображениях
        try:
            years_processed = np.load(os.path.join(OUTPUT_DIR, "years_processed.npy")).tolist()
            print(f"Загружены данные о {len(years_processed)} предобработанных изображениях")

            # Загружаем позиции фрагментов для каждого года
            for year in years_processed:
                positions_file = os.path.join(PATCHES_DIR, str(year), "positions.npy")
                if os.path.exists(positions_file):
                    all_positions[year] = np.load(positions_file).tolist()
                    print(f"Загружены {len(all_positions[year])} позиций фрагментов для {year} года")
                else:
                    print(f"Предупреждение: не найден файл позиций для {year} года")
        except Exception as e:
            print(f"Ошибка при загрузке данных предобработки: {e}")
            print("Убедитесь, что файл years_processed.npy существует в директории results_fullres")
            return

    # Фаза 2: Создание индекса последовательностей
    if skip_phases < 2:
        print("Фаза 2: Создание индекса последовательностей для обучения...")
        sequences_index = build_sequences_index(years_processed, all_positions)

        if not sequences_index:
            print("Не удалось создать индекс последовательностей.")
            return
    else:
        if skip_phases < 3:  # Если мы не пропускаем фазу 3 (обучение), нам нужен индекс
            print("Пропуск Фазы 2 (предполагается, что индекс последовательностей уже создан)")
            # Загружаем индекс последовательностей
            try:
                sequences_index = np.load(os.path.join(OUTPUT_DIR, "sequences_index.npy"), allow_pickle=True).tolist()
                print(f"Загружен индекс с {len(sequences_index)} последовательностями")
            except Exception as e:
                print(f"Ошибка при загрузке индекса последовательностей: {e}")
                print("Убедитесь, что файл sequences_index.npy существует в директории results_fullres")
                return

    # Фаза 3: Обучение модели с использованием генератора, загружающего данные с диска
    if skip_phases < 3:
        print("Фаза 3: Обучение модели...")
        model, history = train_model_with_disk_generator(sequences_index)

        if model is None:
            print("Не удалось обучить модель.")
            # Попробуем загрузить сохраненную модель
            try:
                model_path = os.path.join(OUTPUT_DIR, 'city_growth_model_best.h5')
                print(f"Попытка загрузить сохраненную модель из {model_path}...")
                model = tf.keras.models.load_model(model_path)
                print("Модель успешно загружена!")
            except Exception as e:
                print(f"Ошибка при загрузке модели: {e}")
                return
    else:
        print("Пропуск Фазы 3 (загрузка обученной модели с диска)")
        # Загружаем обученную модель
        try:
            # Пробуем несколько возможных путей к модели
            model_paths = [
                os.path.join(OUTPUT_DIR, 'city_growth_model_best.h5'),
                os.path.join(OUTPUT_DIR, 'city_growth_model_final.h5'),
                os.path.join(OUTPUT_DIR, 'city_growth_model_interrupted.h5')
            ]

            model = None
            for model_path in model_paths:
                if os.path.exists(model_path):
                    print(f"Загрузка модели из {model_path}...")
                    model = tf.keras.models.load_model(model_path)
                    print("Модель успешно загружена!")
                    break

            if model is None:
                print("Ошибка: не найдена сохраненная модель.")
                print(f"Проверьте наличие файлов модели в директории {OUTPUT_DIR}")
                return

        except Exception as e:
            print(f"Ошибка при загрузке модели: {e}")
            import traceback
            traceback.print_exc()
            return

    # Фаза 4: Предсказание следующего года
    print("Фаза 4: Предсказание следующего года...")
    # Берем последние SEQUENCE_LENGTH лет для предсказания
    last_years = sorted(years_processed)[-SEQUENCE_LENGTH:]

    # Выбираем первого года в последовательности, так как его позиции нам нужны для предсказания
    # Этот выбор сохраняет согласованность между фрагментами в разные годы
    first_year_in_seq = last_years[0]

    # Проверяем, что у нас есть позиции для этого года
    if first_year_in_seq not in all_positions or not all_positions[first_year_in_seq]:
        print(f"Ошибка: нет данных о позициях фрагментов для {first_year_in_seq} года")
        return

    next_year, full_prediction = predict_next_year_seamless(model, last_years, all_positions[last_years[0]])

    print("Обработка успешно завершена!")

    # Выводим итоговую информацию
    print("\n--- Итоговая информация ---")
    print(f"Обработано изображений: {len(years_processed)}")
    if sequences_index:
        print(f"Создано последовательностей: {len(sequences_index)}")
    print(f"Предсказан год: {next_year}")

    return model, next_year, full_prediction

model, predicted_year, prediction_image = main(0)

# Дополнительно сохраняем и отображаем результат
if prediction_image is not None:
    final_output_path = os.path.join(BASE_DIR, f"final_prediction_{predicted_year}.png")
    result_img = Image.fromarray((prediction_image * 255).astype(np.uint8))
    result_img.save(final_output_path)
    print(f"\nФинальный результат сохранен в: {final_output_path}")

    try:
        from IPython.display import display
        from IPython.display import Image as IPythonImage
        print("\nВизуализация результата:")
        display(IPythonImage(filename=final_output_path))
    except:
        print("Не удалось отобразить изображение в Colab.")